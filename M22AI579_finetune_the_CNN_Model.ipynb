{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# extracting zip file from drive inside content folder\n",
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/charts.zip', 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "ud3QhSc97xVf"
      },
      "id": "ud3QhSc97xVf",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "c132e6e7",
      "metadata": {
        "id": "c132e6e7"
      },
      "outputs": [],
      "source": [
        "# importing required library \n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import shutil\n",
        "from keras.applications import VGG16\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read the CSV file into a pandas dataframe\n",
        "df = pd.read_csv('./charts/train_val.csv')\n",
        "#df.head()"
      ],
      "metadata": {
        "id": "XwAJ5nnR8Uh2"
      },
      "id": "XwAJ5nnR8Uh2",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the directory where the original chart images are located\n",
        "source_dir = './charts/train_val/'\n",
        "\n",
        "# Define the directory where the separate folders will be created\n",
        "base_dir = './charts/training/'\n",
        "\n",
        "test_dir = './charts/test'\n",
        "\n",
        "# Get the distinct values from a specific column type and define the categories of the chart images\n",
        "categories = df['type'].unique()\n",
        "\n",
        "# print the distinct values\n",
        "print(\"Chart categories: \",categories)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7nvG2h_8awo",
        "outputId": "cca72c8c-1911-43f7-d2e5-437e2f700255"
      },
      "id": "N7nvG2h_8awo",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chart categories:  ['vbar_categorical' 'hbar_categorical' 'line' 'pie' 'dot_line']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step1 : doing image classification\n",
        "# Creating directory and moving data to specific category of charts folder\n",
        "if os.path.isdir(base_dir):\n",
        "    print(\"Directory is already created.\")\n",
        "else:\n",
        "    # iterate over the rows in the dataframe and categorising the data set to specific classes of chart\n",
        "    for image_index, row in df.iterrows():\n",
        "      # extract the filename and label from the row\n",
        "      filename = str(row['image_index'])+('.png')\n",
        "      category = row['type']\n",
        "      if category in categories and os.path.exists(base_dir+category):\n",
        "        #print(\"Directory exists!\")\n",
        "        shutil.move(source_dir + filename, base_dir + category + '/' + filename)\n",
        "      else:\n",
        "        #print(\"Directory does not exist!\")  \n",
        "        os.makedirs(base_dir + category)\n",
        "        shutil.move(source_dir + filename, base_dir + category + '/' + filename)"
      ],
      "metadata": {
        "id": "vx4RY4mj8hfU"
      },
      "id": "vx4RY4mj8hfU",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "9df60b03",
      "metadata": {
        "id": "9df60b03"
      },
      "outputs": [],
      "source": [
        "# Set the input size of the images\n",
        "img_width, img_height = 224, 224\n",
        "# Set the directories of the training and validation data\n",
        "train_data_dir = base_dir\n",
        "val_data_dir = test_dir\n",
        "# Create an instance of the VGG16 model with pre-trained weights\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_width, img_height, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "d784706c",
      "metadata": {
        "id": "d784706c"
      },
      "outputs": [],
      "source": [
        "# Freeze the layers of the pre-trained model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add new layers to the pre-trained model\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Define the new model with the pre-trained model as its base and the new layers as its top\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model with a binary crossentropy loss and an Adam optimizer\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-5), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "c4738cb5",
      "metadata": {
        "id": "c4738cb5"
      },
      "outputs": [],
      "source": [
        "# Performing data augmentation for the training data and validation data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the batch size\n",
        "batch_size = 32\n",
        "\n",
        "# Set the number of training and validation samples\n",
        "nb_train_samples = 800\n",
        "nb_val_samples = 200\n",
        "\n",
        "# Number of epochs setting\n",
        "epochs = 10\n",
        "\n",
        "# Training the model\n",
        "history = model.fit(\n",
        "    train_datagen.flow_from_directory(train_data_dir, target_size=(img_width, img_height), batch_size=batch_size, class_mode='categorical'),\n",
        "    steps_per_epoch=nb_train_samples // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_datagen.flow_from_directory(val_data_dir, target_size=(img_width, img_height), batch_size=batch_size, class_mode='categorical'),\n",
        "    validation_steps=nb_val_samples // batch_size)"
      ],
      "metadata": {
        "id": "5D2vf808M72z"
      },
      "id": "5D2vf808M72z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "04a2d9fa",
      "metadata": {
        "id": "04a2d9fa"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model with the test dataset\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_data_dir =test_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "4f31c249",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f31c249",
        "outputId": "89eaf2b6-01af-46e9-b927-4eb0030d5084"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 images belonging to 0 classes.\n"
          ]
        }
      ],
      "source": [
        "test_data_generator = test_datagen.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f79e1dad",
      "metadata": {
        "id": "f79e1dad",
        "outputId": "ec7fda47-cf3c-4f21-c8c8-e9d2cb8456bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy: 1.0\n",
            "Test loss: 0.0007767498027533293\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = model.evaluate(test_data_generator)\n",
        "print('Test accuracy=', test_acc)\n",
        "print('Test loss=', test_loss)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}